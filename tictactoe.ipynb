{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQYulwksgnbXZiDdAsjt/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshii-02/DL-assignment/blob/main/tictactoe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5eyheUTu0at",
        "outputId": "c0efa23c-f69c-49e5-d551-11fd5e5267a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fast RL agent...\n",
            "Training completed.\n",
            "\n",
            "-------------\n",
            "|   |   | X |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "Row (0-2): 0\n",
            "Col (0-2): 1\n",
            "-------------\n",
            "|   | O | X |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "-------------\n",
            "|   | O | X |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   | X |\n",
            "-------------\n",
            "Row (0-2): 1\n",
            "Col (0-2): 2\n",
            "-------------\n",
            "|   | O | X |\n",
            "-------------\n",
            "|   |   | O |\n",
            "-------------\n",
            "|   |   | X |\n",
            "-------------\n",
            "-------------\n",
            "|   | O | X |\n",
            "-------------\n",
            "|   |   | O |\n",
            "-------------\n",
            "|   | X | X |\n",
            "-------------\n",
            "Row (0-2): 2\n",
            "Col (0-2): 0\n",
            "-------------\n",
            "|   | O | X |\n",
            "-------------\n",
            "|   |   | O |\n",
            "-------------\n",
            "| O | X | X |\n",
            "-------------\n",
            "-------------\n",
            "|   | O | X |\n",
            "-------------\n",
            "|   | X | O |\n",
            "-------------\n",
            "| O | X | X |\n",
            "-------------\n",
            "Row (0-2): 0\n",
            "Col (0-2): 0\n",
            "-------------\n",
            "| O | O | X |\n",
            "-------------\n",
            "|   | X | O |\n",
            "-------------\n",
            "| O | X | X |\n",
            "-------------\n",
            "-------------\n",
            "| O | O | X |\n",
            "-------------\n",
            "| X | X | O |\n",
            "-------------\n",
            "| O | X | X |\n",
            "-------------\n",
            "Tie!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "BOARD_ROWS = 3\n",
        "BOARD_COLS = 3\n",
        "\n",
        "\n",
        "# =========================\n",
        "# STATE (ENVIRONMENT)\n",
        "# =========================\n",
        "class State:\n",
        "    def __init__(self, p1, p2):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.isEnd = False\n",
        "        self.boardHash = None\n",
        "        self.playerSymbol = 1  # p1 starts\n",
        "\n",
        "    def getHash(self):\n",
        "        self.boardHash = str(self.board.reshape(9))\n",
        "        return self.boardHash\n",
        "\n",
        "    def availablePositions(self):\n",
        "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
        "\n",
        "    def updateState(self, position):\n",
        "        self.board[position] = self.playerSymbol\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    def winner(self):\n",
        "        for i in range(3):\n",
        "            if abs(sum(self.board[i, :])) == 3:\n",
        "                self.isEnd = True\n",
        "                return np.sign(sum(self.board[i, :]))\n",
        "            if abs(sum(self.board[:, i])) == 3:\n",
        "                self.isEnd = True\n",
        "                return np.sign(sum(self.board[:, i]))\n",
        "\n",
        "        diag1 = sum(self.board[i, i] for i in range(3))\n",
        "        diag2 = sum(self.board[i, 2 - i] for i in range(3))\n",
        "        if abs(diag1) == 3 or abs(diag2) == 3:\n",
        "            self.isEnd = True\n",
        "            return 1 if diag1 == 3 or diag2 == 3 else -1\n",
        "\n",
        "        if len(self.availablePositions()) == 0:\n",
        "            self.isEnd = True\n",
        "            return 0\n",
        "\n",
        "        self.isEnd = False\n",
        "        return None\n",
        "\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        if result == 1:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif result == -1:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.3)\n",
        "            self.p2.feedReward(0.3)\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((3, 3))\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    # FAST TRAINING\n",
        "    def play(self, rounds=8000):\n",
        "        for _ in range(rounds):\n",
        "            while not self.isEnd:\n",
        "                p1_action = self.p1.chooseAction(\n",
        "                    self.availablePositions(), self.board, self.playerSymbol)\n",
        "                self.updateState(p1_action)\n",
        "                self.p1.addState(self.getHash())\n",
        "\n",
        "                if self.winner() is not None:\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "                p2_action = self.p2.chooseAction(\n",
        "                    self.availablePositions(), self.board, self.playerSymbol)\n",
        "                self.updateState(p2_action)\n",
        "                self.p2.addState(self.getHash())\n",
        "\n",
        "                if self.winner() is not None:\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "            # epsilon decay\n",
        "            self.p1.exp_rate = max(0.01, self.p1.exp_rate * 0.995)\n",
        "            self.p2.exp_rate = max(0.01, self.p2.exp_rate * 0.995)\n",
        "\n",
        "    # HUMAN PLAY\n",
        "    def play2(self):\n",
        "        while not self.isEnd:\n",
        "            positions = self.availablePositions()\n",
        "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "            self.updateState(p1_action)\n",
        "            self.showBoard()\n",
        "\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                print(\"Computer wins!\" if win == 1 else \"Tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "            positions = self.availablePositions()\n",
        "            p2_action = self.p2.chooseAction(positions)\n",
        "            self.updateState(p2_action)\n",
        "            self.showBoard()\n",
        "\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                print(\"Human wins!\" if win == -1 else \"Tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "    def showBoard(self):\n",
        "        for i in range(3):\n",
        "            print('-------------')\n",
        "            for j in range(3):\n",
        "                print('|', 'X' if self.board[i, j] == 1 else 'O' if self.board[i, j] == -1 else ' ', end=' ')\n",
        "            print('|')\n",
        "        print('-------------')\n",
        "\n",
        "\n",
        "# =========================\n",
        "# AI PLAYER\n",
        "# =========================\n",
        "class Player:\n",
        "    def __init__(self, name, exp_rate=0.3):\n",
        "        self.name = name\n",
        "        self.states = []\n",
        "        self.lr = 0.1\n",
        "        self.exp_rate = exp_rate\n",
        "        self.gamma = 0.8\n",
        "        self.states_value = {}\n",
        "\n",
        "    def getHash(self, board):\n",
        "        return str(board.reshape(9))\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        if np.random.rand() < self.exp_rate:\n",
        "            return positions[np.random.choice(len(positions))]\n",
        "        value_max = -999\n",
        "        for p in positions:\n",
        "            next_board = current_board.copy()\n",
        "            next_board[p] = symbol\n",
        "            value = self.states_value.get(self.getHash(next_board), 0)\n",
        "            if value >= value_max:\n",
        "                value_max = value\n",
        "                action = p\n",
        "        return action\n",
        "\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            self.states_value[st] = self.states_value.get(st, 0)\n",
        "            self.states_value[st] += self.lr * (self.gamma * reward - self.states_value[st])\n",
        "            reward = self.states_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        with open('policy_' + self.name, 'wb') as f:\n",
        "            pickle.dump(self.states_value, f)\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        with open(file, 'rb') as f:\n",
        "            self.states_value = pickle.load(f)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# HUMAN PLAYER\n",
        "# =========================\n",
        "class HumanPlayer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def chooseAction(self, positions):\n",
        "        while True:\n",
        "            row = int(input(\"Row (0-2): \"))\n",
        "            col = int(input(\"Col (0-2): \"))\n",
        "            if (row, col) in positions:\n",
        "                return (row, col)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# MAIN\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Training fast RL agent...\")\n",
        "    p1 = Player(\"p1\")\n",
        "    p2 = Player(\"p2\")\n",
        "    st = State(p1, p2)\n",
        "    st.play(8000)\n",
        "\n",
        "    p1.savePolicy()\n",
        "    print(\"Training completed.\\n\")\n",
        "\n",
        "    p1 = Player(\"computer\", exp_rate=0)\n",
        "    p1.loadPolicy(\"policy_p1\")\n",
        "    p2 = HumanPlayer(\"human\")\n",
        "\n",
        "    st = State(p1, p2)\n",
        "\n",
        "    while True:\n",
        "        st.play2()\n",
        "        c = input(\"Play again? (y/n): \")\n",
        "        if c.lower() != 'y':\n",
        "            break\n"
      ]
    }
  ]
}